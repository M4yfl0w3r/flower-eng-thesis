{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOKgMug2qkMvH9Y8ql6V+j7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aSpObtnuBhe",
        "outputId": "1ca44b8b-57d2-43ba-ee0b-beec15469c9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "iWxhYkpHAPFQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision.datasets import ImageFolder"
      ],
      "metadata": {
        "id": "kwNSJa4jNLN2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "kBXfb0R4AXbY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_path  = Path('/content/drive/MyDrive/Dataset/Testing')\n",
        "train_data_path = Path('/content/drive/MyDrive/Dataset/Training')\n",
        "image_path_list = list(Path('/content/drive/MyDrive/Dataset').glob(\"*/*/*.jpg\"))"
      ],
      "metadata": {
        "id": "198ut1SRAa4f"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_transform = transforms.Compose([\n",
        "  transforms.Resize((224, 224)),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize(mean = [0.1855, 0.1855, 0.1855], std = [0.2003, 0.2003, 0.2004])\n",
        "])\n",
        "\n",
        "train_data = ImageFolder(train_data_path, transform = image_transform)\n",
        "train_loader = DataLoader(train_data, batch_size = 8, shuffle = True)\n",
        "test_data = ImageFolder(test_data_path, transform = image_transform)\n",
        "test_loader = DataLoader(test_data, batch_size = 8, shuffle = False)"
      ],
      "metadata": {
        "id": "2kL5tOSXAh2y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "\n",
        "    self.features = nn.Sequential(\n",
        "      nn.Conv2d(3, 16, kernel_size = 3, stride = 1, padding = 1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size = 2, stride = 2, return_indices = True),\n",
        "\n",
        "      nn.Conv2d(16, 16, kernel_size = 3, stride = 1, padding = 1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size = 2, stride = 2, return_indices = True),\n",
        "\n",
        "      nn.Conv2d(16, 16, kernel_size = 3, stride = 1, padding = 1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size = 2, stride = 2, return_indices = True)\n",
        "    )\n",
        "\n",
        "    self.switch_indices = [0] * len(self.features)\n",
        "\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Linear(16 * 28 * 28, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64, 4) # Image classes = 4\n",
        "    )\n",
        "\n",
        "  def forward(self, batch: torch.Tensor):\n",
        "    for i, layer in enumerate(self.features):\n",
        "      if isinstance(layer, nn.MaxPool2d):\n",
        "        batch, indices = layer(batch)\n",
        "        self.switch_indices[i] = indices\n",
        "      else:\n",
        "        batch = layer(batch)\n",
        "\n",
        "    batch = batch.view(batch.size(0), -1)\n",
        "    batch_probabilities = self.classifier(batch)\n",
        "\n",
        "    return batch_probabilities"
      ],
      "metadata": {
        "id": "4R4psoZkuLrz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, num_epochs, train_loader, optimizer, loss_fn):\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for _, (images, labels) in enumerate(train_loader):\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      batch_probabilities = model(images)\n",
        "      loss = loss_fn(batch_probabilities, labels)\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "      _, predicted_labels = torch.max(batch_probabilities, 1)\n",
        "      correct_predictions += (predicted_labels == labels).sum().item()\n",
        "      total_samples += predicted_labels.size(0)\n",
        "\n",
        "    train_accuracy = correct_predictions / total_samples\n",
        "    print(f'Epoch: {epoch} Train accuracy: {train_accuracy}')"
      ],
      "metadata": {
        "id": "wjJwovYGtfC7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def test_model(model, test_loader):\n",
        "  model.eval()\n",
        "\n",
        "  correct_predictions = 0\n",
        "  total_samples = 0\n",
        "\n",
        "  for inputs, labels in test_loader:\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    outputs = model(inputs)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    total_samples += labels.size(0)\n",
        "    correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "  accuracy = correct_predictions / total_samples\n",
        "  print(f\"Accuracy: {accuracy:.2%}\")"
      ],
      "metadata": {
        "id": "jaKGL1Pd-wDu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
      ],
      "metadata": {
        "id": "KBlfOMWSuYON"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, 10, train_loader, optimizer, loss_fn)"
      ],
      "metadata": {
        "id": "lDWGc4g6j33W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c197fc8-35bf-4d00-ade9-07e5b6c4241a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Train accuracy: 0.7930672268907563\n",
            "Epoch: 1 Train accuracy: 0.9108893557422969\n",
            "Epoch: 2 Train accuracy: 0.9483543417366946\n",
            "Epoch: 3 Train accuracy: 0.9698879551820728\n",
            "Epoch: 4 Train accuracy: 0.9772408963585434\n",
            "Epoch: 5 Train accuracy: 0.9879201680672269\n",
            "Epoch: 6 Train accuracy: 0.9858193277310925\n",
            "Epoch: 7 Train accuracy: 0.9956232492997199\n",
            "Epoch: 8 Train accuracy: 0.990546218487395\n",
            "Epoch: 9 Train accuracy: 0.993172268907563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(model, test_loader)"
      ],
      "metadata": {
        "id": "mqs325khj6Eu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "707584e0-b8a8-448e-a0ec-a45abb1440f3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 94.69%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/Models/2411_cnn_model.pth')"
      ],
      "metadata": {
        "id": "5zvUWJChkSeb"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}